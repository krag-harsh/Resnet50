{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.optim as optim\n",
    "import time\n",
    "# import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_ds= torchvision.datasets.CIFAR10(root=\"data/\", train = True, transform=transforms.ToTensor(), download=True)\n",
    "test_ds= torchvision.datasets.CIFAR10(root=\"data/\", train = False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "127.8772378516624"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# len(train_ds) = 50000\n",
    "# len(train_loader) = 391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "train_loader= DataLoader(train_ds, batch_size, shuffle =True)\n",
    "test_leader=  DataLoader(test_ds, batch_size, shuffle = False)\n",
    "# len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:1\" if torch.cuda.is_available else \"cpu\")\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "num_classes=10\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, inplane, planes, stride=1):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        outplane=4*planes\n",
    "        self.conv1 =   nn.Conv2d(inplane, planes,kernel_size=1,bias=False)\n",
    "        self.batchN1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 =   nn.Conv2d(planes, planes,kernel_size=3 ,stride=stride, padding=1 ,bias=False)\n",
    "        self.batchN2 =  nn.BatchNorm2d(planes)\n",
    "        self.conv3 =   nn.Conv2d(planes, outplane,kernel_size=1,bias=False)\n",
    "        self.batchN3 =  nn.BatchNorm2d(outplane)\n",
    "        \n",
    "        self.shortcuts=nn.Sequential()\n",
    "        if(outplane!=inplane or stride!=1):\n",
    "            self.shortcuts = nn.Sequential(nn.Conv2d(inplane, outplane, kernel_size=1,stride=stride,bias=False) ,nn.BatchNorm2d(outplane))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out=F.relu(self.batchN1(self.conv1(x)))\n",
    "        out=F.relu(self.batchN2(self.conv2(out)))\n",
    "        out=self.batchN3(self.conv3(out))\n",
    "        out=F.relu(out+self.shortcuts(x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resmodel(nn.Module):\n",
    "    # def __init__(self, block=Bottleneck, no_bl=[3,4,6,3], output_no=10):\n",
    "    def __init__(self, block, no_bl=[3,4,6,3], output_no=10):\n",
    "        super(Resmodel,self).__init__()\n",
    "        self.in_plane=64\n",
    "        self.conv1= nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1 ,bias=False)\n",
    "        self.batchN11= nn.BatchNorm2d(64)\n",
    "        self.layer1= self._make_layer(block, 64, 3, 1)\n",
    "        self.layer2= self._make_layer(block, 128, 4, 2)\n",
    "        self.layer3= self._make_layer(block, 256, 6, 2)\n",
    "        self.layer4= self._make_layer(block, 512, 3, 2)\n",
    "        self.linear = nn.Linear(2048,10)\n",
    "        \n",
    "    def _make_layer(self, block, plane, numofblock, stride):\n",
    "        layers=[]\n",
    "        strides= [stride] + [1]*(numofblock-1)\n",
    "        for st in strides:\n",
    "            layers.append(Bottleneck(self.in_plane, plane, st))\n",
    "            self.in_plane = plane*4\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #size of x=[batchsize,3,32,32]\n",
    "        out=self.conv1(x)           #after this operation size=[batchsize,64,32,32]\n",
    "        out=self.batchN11(out)\n",
    "        out=F.relu(out)\n",
    "        # out= F.relu(self.batchN11(self.conv1(x)))\n",
    "        out=self.layer1(out)        #after this operation the output size must be [batchsize,256,32,32]\n",
    "        out=self.layer2(out)        #after this operation the output size must be [batchsize,512,16,16]\n",
    "        out=self.layer3(out)        #after this operation the output size must be [batchsize,1024,8,8]\n",
    "        out=self.layer4(out)        #after this operation the output size must be [batchsize,2048,4,4]\n",
    "        out=F.avg_pool2d(out,4)     #after this operation the output size must be [batchsize,2048,1,1]\n",
    "        out= out.view(out.size(0),-1)    #after this operation the output size must be [batchsize,1,2048]\n",
    "        out=self.linear(out)         #after this operation the output size must be [batchsize,1,10]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resmodel(Bottleneck)\n",
    "model=model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer= optim.SGD(model.parameters(), lr= 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/4], Step [200/391], Loss: 0.9331\n",
      "Epoch [2/4], Step [200/391], Loss: 0.7526\n",
      "Epoch [3/4], Step [200/391], Loss: 0.5657\n",
      "Epoch [4/4], Step [200/391], Loss: 0.5027\n",
      "max value of i= 390\n",
      "Finished Training\n",
      "CPU times: user 3min 47s, sys: 1min 28s, total: 5min 16s\n",
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_total_steps = len(train_loader)\n",
    "# max_val_i=0\n",
    "for epoch in range(4):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [128, 3, 32, 32]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(max_val_i<i):\n",
    "            max_val_i=i\n",
    "        # if (i+1) % 20 == 0:\n",
    "        #     print (f'Epoch [{epoch+1}/{4}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# print('max value of i=',max_val_i)\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network: 70.84 %\nAccuracy of plane: 73.5042735042735 %\nAccuracy of car: 84.87394957983193 %\nAccuracy of bird: 57.34265734265734 %\nAccuracy of cat: 58.53658536585366 %\nAccuracy of deer: 59.81308411214953 %\nAccuracy of dog: 49.6124031007752 %\nAccuracy of frog: 86.42857142857143 %\nAccuracy of horse: 78.86178861788618 %\nAccuracy of ship: 82.57575757575758 %\nAccuracy of truck: 83.20610687022901 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_leader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # for i in range(batch_size):\n",
    "        # print(images.shape)\n",
    "        # break\n",
    "        for i in range(16):\n",
    "        # for i in range(128):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# len(test_leader) = 79\n",
    "# len(images)\n",
    "# 79*128 almost equals 10k\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3, 1, 1])\nnew shape= torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# y = torch.randn(1, 3, 4,4)\n",
    "# out=F.avg_pool2d(y,4)\n",
    "# print(out.shape)\n",
    "# out= out.view(out.size(0),-1)\n",
    "# print(\"new shape=\",out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}