{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "\n",
    "# import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "random.seed(100)\n",
    "\n",
    "train_ds= torchvision.datasets.CIFAR10(root=\"data/\", train = True, transform=transforms.ToTensor(), download=True)\n",
    "test_ds= torchvision.datasets.CIFAR10(root=\"data/\", train = False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "train_loader= DataLoader(train_ds, batch_size, shuffle =True)\n",
    "test_leader=  DataLoader(test_ds, batch_size, shuffle = False)\n",
    "# len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:1\" if torch.cuda.is_available else \"cpu\")\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "num_classes=10\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, inplane, planes, stride=1):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        outplane=4*planes\n",
    "        self.conv1 =   nn.Conv2d(inplane, planes,kernel_size=1,bias=False)  #same convolution\n",
    "        self.batchN1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 =   nn.Conv2d(planes, planes,kernel_size=3 ,stride=stride, padding=1 ,bias=False) #if stride is 1 then same convolution\n",
    "        self.batchN2 =  nn.BatchNorm2d(planes)\n",
    "        self.conv3 =   nn.Conv2d(planes, outplane,kernel_size=1,bias=False) #same convolution\n",
    "        self.batchN3 =  nn.BatchNorm2d(outplane)\n",
    "        \n",
    "        self.shortcuts=nn.Sequential()  #creating a shortcut which will help in residual part\n",
    "        if(outplane!=inplane or stride!=1):  #we make the shortcut so that the dimension match \n",
    "            self.shortcuts = nn.Sequential(nn.Conv2d(inplane, outplane, kernel_size=1,stride=stride,bias=False) ,nn.BatchNorm2d(outplane))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out=F.relu(self.batchN1(self.conv1(x)))\n",
    "        out=F.relu(self.batchN2(self.conv2(out)))\n",
    "        out=self.batchN3(self.conv3(out))\n",
    "        out=F.relu(out+self.shortcuts(x))   #most important step of residual network\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resmodel(nn.Module):\n",
    "    # def __init__(self, block=Bottleneck, no_bl=[3,4,6,3], output_no=10):\n",
    "    def __init__(self, block, no_bl=[3,4,6,3], output_no=10):\n",
    "        super(Resmodel,self).__init__()\n",
    "        self.in_plane=64\n",
    "        self.conv1= nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1 ,bias=False)\n",
    "        self.batchN11= nn.BatchNorm2d(64)\n",
    "        self.layer1= self._make_layer(block, 64, 3, 1)\n",
    "        self.layer2= self._make_layer(block, 128, 4, 2)\n",
    "        self.layer3= self._make_layer(block, 256, 6, 2)\n",
    "        self.layer4= self._make_layer(block, 512, 3, 2)\n",
    "        self.linear = nn.Linear(2048,10)    #finally we will classify in 10 class,hence we have 10 dimension\n",
    "        \n",
    "    def _make_layer(self, block, plane, numofblock, stride):\n",
    "        layers=[]\n",
    "        strides= [stride] + [1]*(numofblock-1) #first block will have the given stride rest will have stride=1\n",
    "        #we have stride only for the first bottleneck(that too only one layer of bottleneck will use it)(hence the reduction of dimension due to stride will take place only once for one block of bottleneck)\n",
    "        for st in strides:\n",
    "            layers.append(Bottleneck(self.in_plane, plane, st))\n",
    "            self.in_plane = plane*4     #we know that the last layer in bottleneck is 4 times the size of input layer, hence we multiply it here, so that the first layer of next bottleneck will match the dimension of last layer of previous bottleneck.\n",
    "        return nn.Sequential(*layers)   #*layers will return values stored in the list\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #size of x=[batchsize,3,32,32]\n",
    "        out=self.conv1(x)           #after this operation size=[batchsize,64,32,32]\n",
    "        out=self.batchN11(out)\n",
    "        out=F.relu(out)\n",
    "        # out= F.relu(self.batchN11(self.conv1(x)))\n",
    "        out=self.layer1(out)        #after this operation the output size must be [batchsize,256,32,32]\n",
    "        out=self.layer2(out)        #after this operation the output size must be [batchsize,512,16,16]\n",
    "        out=self.layer3(out)        #after this operation the output size must be [batchsize,1024,8,8]\n",
    "        out=self.layer4(out)        #after this operation the output size must be [batchsize,2048,4,4]\n",
    "        out=F.avg_pool2d(out,4)     #after this operation the output size must be [batchsize,2048,1,1]\n",
    "        out= out.view(out.size(0),-1)    #after this operation the output size must be [batchsize,1,2048]\n",
    "        out=self.linear(out)         #after this operation the output size must be [batchsize,1,10]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try focal losss\n",
    "\n",
    "class focalloss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(focalloss,self).__init__()\n",
    "\n",
    "    def forward(self, inp,targ, alpha=1, gamma=2):\n",
    "        # print(\"shape of input before sigmoid\",inp.shape)  #128*10\n",
    "        inp=F.sigmoid(inp)\n",
    "        inp=inp.view(-1)\n",
    "        # print(\"shape of input after sigmoid\",inp.shape)  #1280\n",
    "        targ=targ.view(-1)\n",
    "        Biloss=F.binary_cross_entropy(inp,targ, reduction='mean')\n",
    "        bi_exp=torch.exp(-Biloss)\n",
    "        focalLoss=alpha*(1-bi_exp)**gamma * Biloss\n",
    "        return focalLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resmodel(Bottleneck)\n",
    "model=model.to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion=focalloss()\n",
    "optimizer= optim.SGD(model.parameters(), lr= 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/harsh19423/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Epoch [1/2], Step [16/391], Loss: 0.0318\n",
      "Epoch [1/2], Step [32/391], Loss: 0.0290\n",
      "Epoch [1/2], Step [48/391], Loss: 0.0268\n",
      "Epoch [1/2], Step [64/391], Loss: 0.0252\n",
      "Epoch [1/2], Step [80/391], Loss: 0.0272\n",
      "Epoch [1/2], Step [96/391], Loss: 0.0243\n",
      "Epoch [1/2], Step [112/391], Loss: 0.0258\n",
      "Epoch [1/2], Step [128/391], Loss: 0.0250\n",
      "Epoch [1/2], Step [144/391], Loss: 0.0249\n",
      "Epoch [1/2], Step [160/391], Loss: 0.0244\n",
      "Epoch [1/2], Step [176/391], Loss: 0.0235\n",
      "Epoch [1/2], Step [192/391], Loss: 0.0245\n",
      "Epoch [1/2], Step [208/391], Loss: 0.0241\n",
      "Epoch [1/2], Step [224/391], Loss: 0.0230\n",
      "Epoch [1/2], Step [240/391], Loss: 0.0239\n",
      "Epoch [1/2], Step [256/391], Loss: 0.0239\n",
      "Epoch [1/2], Step [272/391], Loss: 0.0237\n",
      "Epoch [1/2], Step [288/391], Loss: 0.0232\n",
      "Epoch [1/2], Step [304/391], Loss: 0.0230\n",
      "Epoch [1/2], Step [320/391], Loss: 0.0245\n",
      "Epoch [1/2], Step [336/391], Loss: 0.0245\n",
      "Epoch [1/2], Step [352/391], Loss: 0.0234\n",
      "Epoch [1/2], Step [368/391], Loss: 0.0246\n",
      "Epoch [1/2], Step [384/391], Loss: 0.0239\n",
      "Epoch [2/2], Step [16/391], Loss: 0.0238\n",
      "Epoch [2/2], Step [32/391], Loss: 0.0224\n",
      "Epoch [2/2], Step [48/391], Loss: 0.0225\n",
      "Epoch [2/2], Step [64/391], Loss: 0.0233\n",
      "Epoch [2/2], Step [80/391], Loss: 0.0230\n",
      "Epoch [2/2], Step [96/391], Loss: 0.0240\n",
      "Epoch [2/2], Step [112/391], Loss: 0.0228\n",
      "Epoch [2/2], Step [128/391], Loss: 0.0242\n",
      "Epoch [2/2], Step [144/391], Loss: 0.0228\n",
      "Epoch [2/2], Step [160/391], Loss: 0.0240\n",
      "Epoch [2/2], Step [176/391], Loss: 0.0224\n",
      "Epoch [2/2], Step [192/391], Loss: 0.0245\n",
      "Epoch [2/2], Step [208/391], Loss: 0.0234\n",
      "Epoch [2/2], Step [224/391], Loss: 0.0220\n",
      "Epoch [2/2], Step [240/391], Loss: 0.0228\n",
      "Epoch [2/2], Step [256/391], Loss: 0.0246\n",
      "Epoch [2/2], Step [272/391], Loss: 0.0240\n",
      "Epoch [2/2], Step [288/391], Loss: 0.0219\n",
      "Epoch [2/2], Step [304/391], Loss: 0.0228\n",
      "Epoch [2/2], Step [320/391], Loss: 0.0216\n",
      "Epoch [2/2], Step [336/391], Loss: 0.0222\n",
      "Epoch [2/2], Step [352/391], Loss: 0.0225\n",
      "Epoch [2/2], Step [368/391], Loss: 0.0222\n",
      "Epoch [2/2], Step [384/391], Loss: 0.0230\n",
      "Epoch [3/2], Step [16/391], Loss: 0.0231\n",
      "Epoch [3/2], Step [32/391], Loss: 0.0228\n",
      "Epoch [3/2], Step [48/391], Loss: 0.0226\n",
      "Epoch [3/2], Step [64/391], Loss: 0.0215\n",
      "Epoch [3/2], Step [80/391], Loss: 0.0217\n",
      "Epoch [3/2], Step [96/391], Loss: 0.0225\n",
      "Epoch [3/2], Step [112/391], Loss: 0.0225\n",
      "Epoch [3/2], Step [128/391], Loss: 0.0211\n",
      "Epoch [3/2], Step [144/391], Loss: 0.0236\n",
      "Epoch [3/2], Step [160/391], Loss: 0.0214\n",
      "Epoch [3/2], Step [176/391], Loss: 0.0211\n",
      "Epoch [3/2], Step [192/391], Loss: 0.0210\n",
      "Epoch [3/2], Step [208/391], Loss: 0.0223\n",
      "Epoch [3/2], Step [224/391], Loss: 0.0221\n",
      "Epoch [3/2], Step [240/391], Loss: 0.0223\n",
      "Epoch [3/2], Step [256/391], Loss: 0.0215\n",
      "Epoch [3/2], Step [272/391], Loss: 0.0237\n",
      "Epoch [3/2], Step [288/391], Loss: 0.0216\n",
      "Epoch [3/2], Step [304/391], Loss: 0.0220\n",
      "Epoch [3/2], Step [320/391], Loss: 0.0216\n",
      "Epoch [3/2], Step [336/391], Loss: 0.0211\n",
      "Epoch [3/2], Step [352/391], Loss: 0.0225\n",
      "Epoch [3/2], Step [368/391], Loss: 0.0213\n",
      "Epoch [3/2], Step [384/391], Loss: 0.0231\n",
      "Epoch [4/2], Step [16/391], Loss: 0.0224\n",
      "Epoch [4/2], Step [32/391], Loss: 0.0200\n",
      "Epoch [4/2], Step [48/391], Loss: 0.0219\n",
      "Epoch [4/2], Step [64/391], Loss: 0.0214\n",
      "Epoch [4/2], Step [80/391], Loss: 0.0193\n",
      "Epoch [4/2], Step [96/391], Loss: 0.0204\n",
      "Epoch [4/2], Step [112/391], Loss: 0.0200\n",
      "Epoch [4/2], Step [128/391], Loss: 0.0200\n",
      "Epoch [4/2], Step [144/391], Loss: 0.0196\n",
      "Epoch [4/2], Step [160/391], Loss: 0.0198\n",
      "Epoch [4/2], Step [176/391], Loss: 0.0218\n",
      "Epoch [4/2], Step [192/391], Loss: 0.0206\n",
      "Epoch [4/2], Step [208/391], Loss: 0.0199\n",
      "Epoch [4/2], Step [224/391], Loss: 0.0216\n",
      "Epoch [4/2], Step [240/391], Loss: 0.0197\n",
      "Epoch [4/2], Step [256/391], Loss: 0.0215\n",
      "Epoch [4/2], Step [272/391], Loss: 0.0195\n",
      "Epoch [4/2], Step [288/391], Loss: 0.0201\n",
      "Epoch [4/2], Step [304/391], Loss: 0.0188\n",
      "Epoch [4/2], Step [320/391], Loss: 0.0187\n",
      "Epoch [4/2], Step [336/391], Loss: 0.0207\n",
      "Epoch [4/2], Step [352/391], Loss: 0.0192\n",
      "Epoch [4/2], Step [368/391], Loss: 0.0197\n",
      "Epoch [4/2], Step [384/391], Loss: 0.0196\n",
      "Epoch [5/2], Step [16/391], Loss: 0.0184\n",
      "Epoch [5/2], Step [32/391], Loss: 0.0194\n",
      "Epoch [5/2], Step [48/391], Loss: 0.0193\n",
      "Epoch [5/2], Step [64/391], Loss: 0.0185\n",
      "Epoch [5/2], Step [80/391], Loss: 0.0191\n",
      "Epoch [5/2], Step [96/391], Loss: 0.0192\n",
      "Epoch [5/2], Step [112/391], Loss: 0.0188\n",
      "Epoch [5/2], Step [128/391], Loss: 0.0196\n",
      "Epoch [5/2], Step [144/391], Loss: 0.0209\n",
      "Epoch [5/2], Step [160/391], Loss: 0.0176\n",
      "Epoch [5/2], Step [176/391], Loss: 0.0190\n",
      "Epoch [5/2], Step [192/391], Loss: 0.0196\n",
      "Epoch [5/2], Step [208/391], Loss: 0.0202\n",
      "Epoch [5/2], Step [224/391], Loss: 0.0177\n",
      "Epoch [5/2], Step [240/391], Loss: 0.0192\n",
      "Epoch [5/2], Step [256/391], Loss: 0.0190\n",
      "Epoch [5/2], Step [272/391], Loss: 0.0187\n",
      "Epoch [5/2], Step [288/391], Loss: 0.0196\n",
      "Epoch [5/2], Step [304/391], Loss: 0.0183\n",
      "Epoch [5/2], Step [320/391], Loss: 0.0193\n",
      "Epoch [5/2], Step [336/391], Loss: 0.0192\n",
      "Epoch [5/2], Step [352/391], Loss: 0.0196\n",
      "Epoch [5/2], Step [368/391], Loss: 0.0194\n",
      "Epoch [5/2], Step [384/391], Loss: 0.0173\n",
      "Epoch [6/2], Step [16/391], Loss: 0.0186\n",
      "Epoch [6/2], Step [32/391], Loss: 0.0182\n",
      "Epoch [6/2], Step [48/391], Loss: 0.0188\n",
      "Epoch [6/2], Step [64/391], Loss: 0.0188\n",
      "Epoch [6/2], Step [80/391], Loss: 0.0178\n",
      "Epoch [6/2], Step [96/391], Loss: 0.0204\n",
      "Epoch [6/2], Step [112/391], Loss: 0.0164\n",
      "Epoch [6/2], Step [128/391], Loss: 0.0187\n",
      "Epoch [6/2], Step [144/391], Loss: 0.0177\n",
      "Epoch [6/2], Step [160/391], Loss: 0.0183\n",
      "Epoch [6/2], Step [176/391], Loss: 0.0187\n",
      "Epoch [6/2], Step [192/391], Loss: 0.0185\n",
      "Epoch [6/2], Step [208/391], Loss: 0.0172\n",
      "Epoch [6/2], Step [224/391], Loss: 0.0181\n",
      "Epoch [6/2], Step [240/391], Loss: 0.0192\n",
      "Epoch [6/2], Step [256/391], Loss: 0.0200\n",
      "Epoch [6/2], Step [272/391], Loss: 0.0172\n",
      "Epoch [6/2], Step [288/391], Loss: 0.0187\n",
      "Epoch [6/2], Step [304/391], Loss: 0.0178\n",
      "Epoch [6/2], Step [320/391], Loss: 0.0189\n",
      "Epoch [6/2], Step [336/391], Loss: 0.0187\n",
      "Epoch [6/2], Step [352/391], Loss: 0.0180\n",
      "Epoch [6/2], Step [368/391], Loss: 0.0186\n",
      "Epoch [6/2], Step [384/391], Loss: 0.0166\n",
      "Epoch [7/2], Step [16/391], Loss: 0.0185\n",
      "Epoch [7/2], Step [32/391], Loss: 0.0163\n",
      "Epoch [7/2], Step [48/391], Loss: 0.0171\n",
      "Epoch [7/2], Step [64/391], Loss: 0.0204\n",
      "Epoch [7/2], Step [80/391], Loss: 0.0181\n",
      "Epoch [7/2], Step [96/391], Loss: 0.0161\n",
      "Epoch [7/2], Step [112/391], Loss: 0.0160\n",
      "Epoch [7/2], Step [128/391], Loss: 0.0167\n",
      "Epoch [7/2], Step [144/391], Loss: 0.0172\n",
      "Epoch [7/2], Step [160/391], Loss: 0.0170\n",
      "Epoch [7/2], Step [176/391], Loss: 0.0182\n",
      "Epoch [7/2], Step [192/391], Loss: 0.0176\n",
      "Epoch [7/2], Step [208/391], Loss: 0.0182\n",
      "Epoch [7/2], Step [224/391], Loss: 0.0193\n",
      "Epoch [7/2], Step [240/391], Loss: 0.0148\n",
      "Epoch [7/2], Step [256/391], Loss: 0.0178\n",
      "Epoch [7/2], Step [272/391], Loss: 0.0154\n",
      "Epoch [7/2], Step [288/391], Loss: 0.0165\n",
      "Epoch [7/2], Step [304/391], Loss: 0.0171\n",
      "Epoch [7/2], Step [320/391], Loss: 0.0181\n",
      "Epoch [7/2], Step [336/391], Loss: 0.0171\n",
      "Epoch [7/2], Step [352/391], Loss: 0.0152\n",
      "Epoch [7/2], Step [368/391], Loss: 0.0167\n",
      "Epoch [7/2], Step [384/391], Loss: 0.0160\n",
      "Epoch [8/2], Step [16/391], Loss: 0.0181\n",
      "Epoch [8/2], Step [32/391], Loss: 0.0174\n",
      "Epoch [8/2], Step [48/391], Loss: 0.0182\n",
      "Epoch [8/2], Step [64/391], Loss: 0.0165\n",
      "Epoch [8/2], Step [80/391], Loss: 0.0153\n",
      "Epoch [8/2], Step [96/391], Loss: 0.0192\n",
      "Epoch [8/2], Step [112/391], Loss: 0.0159\n",
      "Epoch [8/2], Step [128/391], Loss: 0.0161\n",
      "Epoch [8/2], Step [144/391], Loss: 0.0166\n",
      "Epoch [8/2], Step [160/391], Loss: 0.0178\n",
      "Epoch [8/2], Step [176/391], Loss: 0.0171\n",
      "Epoch [8/2], Step [192/391], Loss: 0.0176\n",
      "Epoch [8/2], Step [208/391], Loss: 0.0148\n",
      "Epoch [8/2], Step [224/391], Loss: 0.0160\n",
      "Epoch [8/2], Step [240/391], Loss: 0.0167\n",
      "Epoch [8/2], Step [256/391], Loss: 0.0147\n",
      "Epoch [8/2], Step [272/391], Loss: 0.0167\n",
      "Epoch [8/2], Step [288/391], Loss: 0.0174\n",
      "Epoch [8/2], Step [304/391], Loss: 0.0182\n",
      "Epoch [8/2], Step [320/391], Loss: 0.0149\n",
      "Epoch [8/2], Step [336/391], Loss: 0.0163\n",
      "Epoch [8/2], Step [352/391], Loss: 0.0161\n",
      "Epoch [8/2], Step [368/391], Loss: 0.0149\n",
      "Epoch [8/2], Step [384/391], Loss: 0.0164\n",
      "Epoch [9/2], Step [16/391], Loss: 0.0147\n",
      "Epoch [9/2], Step [32/391], Loss: 0.0159\n",
      "Epoch [9/2], Step [48/391], Loss: 0.0172\n",
      "Epoch [9/2], Step [64/391], Loss: 0.0163\n",
      "Epoch [9/2], Step [80/391], Loss: 0.0139\n",
      "Epoch [9/2], Step [96/391], Loss: 0.0145\n",
      "Epoch [9/2], Step [112/391], Loss: 0.0151\n",
      "Epoch [9/2], Step [128/391], Loss: 0.0152\n",
      "Epoch [9/2], Step [144/391], Loss: 0.0166\n",
      "Epoch [9/2], Step [160/391], Loss: 0.0154\n",
      "Epoch [9/2], Step [176/391], Loss: 0.0162\n",
      "Epoch [9/2], Step [192/391], Loss: 0.0162\n",
      "Epoch [9/2], Step [208/391], Loss: 0.0146\n",
      "Epoch [9/2], Step [224/391], Loss: 0.0154\n",
      "Epoch [9/2], Step [240/391], Loss: 0.0166\n",
      "Epoch [9/2], Step [256/391], Loss: 0.0146\n",
      "Epoch [9/2], Step [272/391], Loss: 0.0142\n",
      "Epoch [9/2], Step [288/391], Loss: 0.0152\n",
      "Epoch [9/2], Step [304/391], Loss: 0.0174\n",
      "Epoch [9/2], Step [320/391], Loss: 0.0157\n",
      "Epoch [9/2], Step [336/391], Loss: 0.0161\n",
      "Epoch [9/2], Step [352/391], Loss: 0.0172\n",
      "Epoch [9/2], Step [368/391], Loss: 0.0139\n",
      "Epoch [9/2], Step [384/391], Loss: 0.0162\n",
      "Epoch [10/2], Step [16/391], Loss: 0.0153\n",
      "Epoch [10/2], Step [32/391], Loss: 0.0178\n",
      "Epoch [10/2], Step [48/391], Loss: 0.0139\n",
      "Epoch [10/2], Step [64/391], Loss: 0.0154\n",
      "Epoch [10/2], Step [80/391], Loss: 0.0150\n",
      "Epoch [10/2], Step [96/391], Loss: 0.0151\n",
      "Epoch [10/2], Step [112/391], Loss: 0.0155\n",
      "Epoch [10/2], Step [128/391], Loss: 0.0151\n",
      "Epoch [10/2], Step [144/391], Loss: 0.0153\n",
      "Epoch [10/2], Step [160/391], Loss: 0.0144\n",
      "Epoch [10/2], Step [176/391], Loss: 0.0151\n",
      "Epoch [10/2], Step [192/391], Loss: 0.0148\n",
      "Epoch [10/2], Step [208/391], Loss: 0.0142\n",
      "Epoch [10/2], Step [224/391], Loss: 0.0134\n",
      "Epoch [10/2], Step [240/391], Loss: 0.0157\n",
      "Epoch [10/2], Step [256/391], Loss: 0.0156\n",
      "Epoch [10/2], Step [272/391], Loss: 0.0141\n",
      "Epoch [10/2], Step [288/391], Loss: 0.0152\n",
      "Epoch [10/2], Step [304/391], Loss: 0.0156\n",
      "Epoch [10/2], Step [320/391], Loss: 0.0149\n",
      "Epoch [10/2], Step [336/391], Loss: 0.0139\n",
      "Epoch [10/2], Step [352/391], Loss: 0.0169\n",
      "Epoch [10/2], Step [368/391], Loss: 0.0164\n",
      "Epoch [10/2], Step [384/391], Loss: 0.0164\n",
      "Finished Training\n",
      "CPU times: user 10min 4s, sys: 3min 13s, total: 13min 18s\n",
      "Wall time: 13min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_total_steps = len(train_loader)\n",
    "NOepo=10\n",
    "for epoch in range(NOepo):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [128, 3, 32, 32]\n",
    "        images = images.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        #for focal loss:\n",
    "        labels= F.one_hot(labels, num_classes=10)       \n",
    "        labels= labels.type(torch.FloatTensor)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # break\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 16 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{2}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# print('max value of i=',max_val_i)\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network: 33.63 %\nAccuracy of plane: 35.7 %\nAccuracy of car: 52.2 %\nAccuracy of bird: 6.8 %\nAccuracy of cat: 14.5 %\nAccuracy of deer: 38.0 %\nAccuracy of dog: 32.3 %\nAccuracy of frog: 34.5 %\nAccuracy of horse: 31.1 %\nAccuracy of ship: 50.6 %\nAccuracy of truck: 40.6 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_leader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # for i in range(batch_size):\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}